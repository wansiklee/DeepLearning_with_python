{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "4장_머신러닝의기본요소.ipynb",
      "version": "0.3.2",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VhH9AQfMSC63",
        "colab_type": "text"
      },
      "source": [
        "# 4장 머신 러닝의 기본 요소\n",
        "\n",
        "[케라스 창시자에게 배우는 딥러닝] 책을 기반으로 제가 정리하고 요약한 내용입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xU6NKoFKSC64",
        "colab_type": "text"
      },
      "source": [
        "## 4.1 머신 러닝의 네 가지 분류\n",
        "\n",
        "3장에서는 **지도 학습**(supervised learning)의 예인 이진 분류, 다중 분류, 스칼라 휘귀를 배웠습니다. 지도 학습은 훈련 데이터의 입력과 타깃 사이에 있는 관계를 학습하는 것입니다. 일반적인 머신 러닝은 4개의 커다란 범주 안에 속합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5hOJGlsSC65",
        "colab_type": "text"
      },
      "source": [
        "### 4.1.1 지도학습\n",
        "\n",
        "가장 흔한 경우입니다. 샘플 데이터가 주어지면 알고 있는 타깃에 입력 데이터를 매핑하는 방법을 학습합니다. 지금까지 본 예제는 모두 지도 학습의 고전적 예입니다. 지도 학습은 대부분 분류와 회귀로 구성되지만 다음과 같은 변종도 많습니다.\n",
        "* 시퀀스 생성: 사진이 주어지면 이를 설명하는 캡션을 생성합니다.\n",
        "* 구문 트리 예측: 문장이 주어지면 분해된 구문 트리를 예측합니다.\n",
        "* 물체 감지(object detection): 사진이 주어지면 사진 안의 특정 물체 주위에 경계 상자(bounding box)를 그립니다.\n",
        "* 이미지 분할(image segmentation): 사진이 주어졌을 때 픽셀 단위로 특정 물체에 마스킹을 합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "URmfsvOZSC66",
        "colab_type": "text"
      },
      "source": [
        "### 4.1.2 비지도 학습\n",
        "\n",
        "어떤 타깃도 사용하지 않고 입력 데이터에 대한 흥미로운 변환을 찾습니다. 데이터 시각화, 데이터 압축, 데이터의 노이즈 제거 또는 데이터에 있는 상관관계를 더 잘 이해하기 위해 사용합니다. **비지도 학습**(unsupervised learning)은 데이터 분석에서 빼놓을 수 없는 요소이며, 종종 지도 학습 문제를 풀기 전에 데이터셋을 잘 이해하기 위해 필수적으로 거치는 단계입니다. **차원 축소**와 **군집**이 잘 알려진 범주입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_nLCzzqHSC67",
        "colab_type": "text"
      },
      "source": [
        "### 4.1.3 자기 지도 학습\n",
        "\n",
        "**자기 지도 학습**은 지도 학습이지만 사람이 만든 레이블을 사용하지 않습니다. 보통 레이블을 경험적인 알고리즘을 사용해서 입력 데이터로부터 생성합니다. 예를 들어 **오토인코더**가 예입니다. 여기에서 생성된 타깃은 수정하지 않은 원본 입력입니다.  \n",
        "\n",
        "범주에 명확한 경계가 없기 때문에 자기 지도 학습은 학습 메커니즘과 애플리케이션 측면 중 어디에 중점을 두는지에 따라 지도 학습 또는 비지도 학습으로 재해석 될 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-epjTV2SC68",
        "colab_type": "text"
      },
      "source": [
        "### 4.1.4 강화 학습\n",
        "\n",
        "강화 학습에서 **에이전트**는 환경에 대한 정보를 받아 보상을 최대화하는 행동을 선택하도록 학습됩니다. 예를 들어 구글 딥마인드의 알파고가 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0795aDp9SC69",
        "colab_type": "text"
      },
      "source": [
        "## 4.2 머신 러닝 모델 평가\n",
        "\n",
        "머신 러닝의 목표는 처음 본 데이터에서 잘 작동하는 **일반화**된 모델을 얻는 것입니다. 이 절에서는 일반화, 즉 머신 러닝 모델의 성능을 어떻게 측정하는지에 집중합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPOxGctKSC69",
        "colab_type": "text"
      },
      "source": [
        "### 4.2.1 훈련, 검증, 테스트 세트\n",
        "\n",
        "모델 평가의 핵심은 가용한 데이터를 항상 훈련, 검증, 테스트 3개의 세트로 나누는 것입니다.\n",
        "1. 훈련 세트에서 모델을 훈련하고\n",
        "2. 검증 세트에서 모델을 평가하고\n",
        "3. 테스트 세트에서 최종적으로 딱 한 번 모델을 테스트합니다.\n",
        "\n",
        "검증 세트가 필요한 이유는 모델을 개발할 때 항상 모델의 설정을 튜닝하기 때문입니다. 검증 세트에서 모델의 성능을 평가하여 **하이퍼파라미터** 튜닝을 수행합니다. 본직적으로 이런 튜닝도 **학습**이기 때문에 검증 세트에 오버피팅 될 수 있습니다.  \n",
        "\n",
        "이 현상의 핵심은 **정보 누설** 개념에 있습니다. 검증 세트의 모델 성능에 기반하여 모델의 하이퍼파라미터를 조정할 때마다 검증 데이터에 관한 정보가 모델로 새는 것입니다. 결국 검증 데이터에 맞추어 최적화했기 때문에 검증 데이터에 의도적으로 잘 수행되는 모델이 만들어집니다.\n",
        "\n",
        "검증 데이터가 아니고 완전히 새로운 데이터에 대한 성능이 관심 대상이라면 이전에 본 적 없는 완전히 다른 데이터셋인 테스트 세트를 사용해야 합니다. 즉, 테스트 세트는 학습에 관여를 해서는 안됩니다.\n",
        "\n",
        "다음은 데이터가 적을 때 사용하는 세 가지 평가 방법입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQMbafMjSC6-",
        "colab_type": "text"
      },
      "source": [
        "**단순 홀드아웃 검증**\n",
        "\n",
        "* 데이터의 일정량을 테스트 세트로 떼어 놓습니다.\n",
        "* 남은 데이터에서 훈련하고 테스트 세트로  평가합니다.\n",
        "\n",
        "이 평가 방법의 단점은 데이터가 적을 때는 검증 세트와 테스트 세트의 샘플이 너무 적어 주어진 전체 데이터를 통계적으로 대표하지 못할 수 있습니다. 다른 난수 초깃값으로 셔플링해서 데이터를 나누었을 때 모델의 성능이 달라지는 것으로 이 문제를 확인할 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAp6-5VqSC6_",
        "colab_type": "text"
      },
      "source": [
        "**K-겹 교차 검증**\n",
        "\n",
        "* 데이터를 동일한 크기를 가진 K개 분할로 나눕니다.\n",
        "* 각 분할 i에 대해 남은 K-1개의 분할로 모델을 훈련하고 분할 i에서 모델을 평가합니다.\n",
        "* K개의 점수를 평균하여 최종 점수를 얻습니다.\n",
        "\n",
        "이 방법은 모델의 성능이 데이터 분할에 따라 편차가 클 때 도움이 됩니다. 홀드 아웃 검증처럼 이 방법은 모델의 튜닝에 별개의 검증 세트를 사용하게 됩니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqLqeZb2SC7A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 코드 4-2 K-겹 교차 검증 구현 예\n",
        "\n",
        "k = 4\n",
        "num_validation_samples = len(data) // k\n",
        "\n",
        "np.random.shuffle(data)\n",
        "\n",
        "validation_scores = []\n",
        "for fold in range(k):\n",
        "    validation_data = data[num_validation_samples * fold: num_validation_samples * (fold+1)]\n",
        "    training_data = data[:num_validation_samples * fold] + data[num_validation_samples * (fold+1):]\n",
        "    \n",
        "    model = get_model()\n",
        "    model.train(training_data)\n",
        "    validation_score = model.evaluate(validation_data)\n",
        "    valdation_scores.append(validation_score)\n",
        "    \n",
        "    validation_score = np.average(validation_scores)\n",
        "    \n",
        "    model = get_model()\n",
        "    model.train(data)\n",
        "    test_score = model.evaluate(test_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJbzjHRZSC7E",
        "colab_type": "text"
      },
      "source": [
        "**셔플링을 사용한 반복 K-겹 교차 검증**\n",
        "\n",
        "이 방법은 비교적 가용 데이터가 적고 가능한 정확하게 모델을 평가하고자 할 때 사용합니다.\n",
        "* K-겹 교차 검증을 여러 번 적용하되\n",
        "* K개의 분할로 나누기 전에 매번 데이터를 무작위로 섞습니다.\n",
        "* 모든 K-겹 교차 검증을 실행해서 얻은 점수의 평균이 최종 점수가 됩니다.\n",
        "\n",
        "결국 반복횟수 * K개의 모델을 훈련하고 평가하므로 비용이 매우 많이 듭니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eF5jNONmSC7F",
        "colab_type": "text"
      },
      "source": [
        "### 4.2.2 기억해야 할 것\n",
        "\n",
        "평가 방식을 선택할 때 다음 사항을 유념해야 합니다.\n",
        "* **대표성 있는 데이터**: 훈련 세트와 테스트 세트가 주어진 데이터에 대한 대표성이 있어야 합니다.\n",
        "* **시간의 방향**: 과거로부터 미래를 예측하려고 한다면 무작위로 섞어서는 절대 안되고 훈련 세트에 있는 데이터보다 테스트 세트에 있는 모든 데이터가 미래의 것이어야 합니다.\n",
        "* **데이터 중복**: 훈련 세트와 검증 세트가 중복되면 훈련 테스트의 일부로 검증하는 최악의 경우가 되므로 중복되지 않는지 확인해야 합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y32MFwQDSC7G",
        "colab_type": "text"
      },
      "source": [
        "## 4.3 데이터 전처리, 특성 공학, 특성 학습"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQEtWhDhSC7H",
        "colab_type": "text"
      },
      "source": [
        "### 4.3.1 신경망을 위한 데이터 전처리\n",
        "\n",
        "데이터 전처리 목적은 주어진 원본 데이터를 신경망에 적용하기 쉽도록 만드는 것입니다"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXDBknqdSC7H",
        "colab_type": "text"
      },
      "source": [
        "**벡터화**\n",
        "\n",
        "신경망에서 모든 입력과 타깃은 부동 소수 데이터로 이루어진 텐서(특정 경우에 정수 텐서)여야 합니다. 처리해야 할 것이 무엇이든지 먼저 텐서로 변환해야 합니다. 이 단계를 데이터 벡터화라고 합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itlLLJ_JSC7I",
        "colab_type": "text"
      },
      "source": [
        "**값 정규화**\n",
        "\n",
        "네트워크를 쉽게 학습시키려면 데이터가 다음 특징을 따라야 합니다.\n",
        "* 작은 값을 취합니다. 일반적으로 대부분의 값이 0~1 사이여야 합니다.\n",
        "* 균일해야 합니다. 즉 모든 특성이 대체로 비슷한 범위를 가져야 합니다.\n",
        "\n",
        "추가적으로 다음에 나오는 정규화 방법은 꼭 필수적이지는 않지만 자주 사용되고 도움이 될 수  있습니다.\n",
        "* 각 특성별로 평균이 0이 되도록 정규화합니다.\n",
        "* 각 특성별로 표준 편차가 1이 되도록 정규화합니다.\n",
        "\n",
        "x가 (샘플,특성) 크기가 2D 행렬이라고 가정하면  \n",
        "\n",
        "```x -= x.mean(axis=0)```\n",
        "\n",
        "```x /= x.std(axis=0)```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fulLlAqfSC7J",
        "colab_type": "text"
      },
      "source": [
        "**누락된 값 다루기**\n",
        "\n",
        "일반적으로 신경망에서 0이 사전에 정의된 의미 있는 값이 아니라면 누락된 값을 0으로 입력해도 괜찮습니다. 네트워크가 0이 누락된 데이터를 의미한다는 것을 학습하면 이 값을 무시하기 시작할 것입니다.  \n",
        "\n",
        "테스트 데이터에 누락된 값이 포함될 가능성이 있다고 가정합시다. 하지만 네트워크가 누락된 값이 없는 데이터에서 훈련되었다면 이 네트워크는 누락된 값을 무시하는 법을 알지 못합니다. 이런 경우에는 누락된 값이 있는 훈련 샘플을 고의적으로 만들어야 합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUjmODihSC7K",
        "colab_type": "text"
      },
      "source": [
        "### 4.3.2 특성 공학\n",
        "\n",
        "특성 공학은 데이터와 머신 러닝 알고리즘에 관한 지식을 사용하는 단계입니다. 모델에 데이터를 주입하기 전에 하드코딩된 변환을 적용하여 알고리즘이 더 잘 수행되도록 만들어 줍니다. 데이터에 대한 이해도가 높을수록 특성을 더 간단한 방식으로 표현하여 문제를 쉽게 만듭니다.  \n",
        "\n",
        "최근 딥러닝은 대부분 특성 공학이 필요하지 않습니다. 신경망이 자동으로 원본 데이터에서 유용한 특성을 추출할 수 있기 때문입니다. 그렇지만 특성 공학은 필요합니다.\n",
        "* 좋은 특성은 적은 자원을 사용하여 문제를 더 멋지게 풀어낼 수 있습니다.\n",
        "* 좋은 특성은 더 적은 데이터로 문제를 풀 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZiaKSEcSC7L",
        "colab_type": "text"
      },
      "source": [
        "## 4.4 과대적합과 과소적합\n",
        "\n",
        "머신 러닝의 근본적인 이슈는 최적화와 일반화 사이의 줄다리기입니다.\n",
        "* **최적화**(optimization)는 가능한 훈련 데이터에서 최고의 성능을 얻으려고 모델을 조정하는 과정입니다.(머신 러닝의 학습)\n",
        "* **일반화**(generalization)는 훈련된 모델이 이전에 본 적 없는 데이터에서 얼마나 잘 수행되는지 의미합니다.\n",
        "\n",
        "훈련 초기에 최적화와 일반화는 상호 연관되어 있습니다.  \n",
        "훈련 데이터의 손실이 낮아질수록 테스트 데이터의 손실도 낮아집니다. 이런 상황에서 모델이 **과소적합**(underfitting)되었다고 합니다. 모델의 성능이 계속 발전될 여지가 있습니다. 즉 네트워크가 훈련 데이터에 있는 관련 특성을 모두 학습하지 못했습니다.\n",
        "\n",
        "하지만 훈련 데이터에 여러 번 반복 학습하고 나면 어느 시점부터 일반화 성능이 더 이상 높아지지 않습니다. 검증 세트의 성능이 멈추고 감소되기 시작합니다. 즉 모델이 **과대적합**(overfitting)되기 시작합니다. 이는 훈련 데이터에 특화된 패턴을 학습하기 시작했다는 의미입니다.\n",
        "\n",
        "이런 현상을 막기 위한 가장 좋은 방법은 **훈련 데이터를 많이 모으는 것입니다**. 하지만 데이터를 더 모으는 것이 불가능할 때 차선책은 모델이 수용할 수 있는 정보의 양을 조절하거나 저장할 수 있는 정보에 제약을 가하는 것입니다. 이런 식으로 과대적합을 피하는 처리 과정을 **규제**(regularization)라고 합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mY6501gcSC7L",
        "colab_type": "text"
      },
      "source": [
        "### 4.4.1 네트워크 크기 축소\n",
        "\n",
        "과대적합을 막는 가장 단순한 방법은 모델의 크기, 즉 모델에 있는 학습 파라미터의 수를 줄이는 것입니다. 파라미터의 수는 층의 수와 각 층의 유닛 수에 의해 결정됩니다. 딥러닝에서 모델에 있는 학습 파라미터의 수를 종종 모델의 용량(capacity)이라고 말합니다.\n",
        "\n",
        "파라미터가 많다면, 훈련 샘플과 타깃 사이를 일대일 매핑으로 완변하게 학습할 수 있으나, 이는 일반화 능력이 없습니다. 파라미터가 적다면, 과소적합이 일어나게 됩니다. 그렇기에 머신 러닝에 있어서는 너무 많은 용량과 충분하지 않은 용량 사이의 절충점을 찾아야 합니다.\n",
        "\n",
        "이에 대한 공식은 없습니다. 각기 다른 구조로 테스트하며 절충점을 찾아야합니다. 적절한 모델 크기를 찾는 일반적인 작업 흐름은 비교적 적은 수의 층과 파라미터로 시작하여 검증 손실이 감소되기 시작할 때까지 층이나 유닛의 수를 늘리는 것입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPUUQK79SC7M",
        "colab_type": "text"
      },
      "source": [
        "### 4.4.2 가중치 규제 추가\n",
        "\n",
        "오캄의 면도날 이론은 어떤 것에 대한 두 가지의 설명이 있다면 더 적은 가정이 필요한 간단한 설명이 옳을 것이라는 이론입니다.\n",
        "\n",
        "이 개념은 신경망에서도 적용됩니다. 간단한 모델이 복잡한 모델보다 과대적합 될 가능성이 적습니다. 여기서 간단한 모델은 적은 수의 파라미터를 가진 모델입니다. 그리므로 과대적합을 완화하기 위한 일반적인 방법은  네트워크의 복잡도에 제한을 두어 가중치가 작은 값을 가지도록 하는 것입니다. 가중치 값의 분포가 더 균일하게 됩니다. 이를 **가중치 규제**(weight regularization)라고 하며, 네트워크의 손실 함수에 큰 가중치에 연관된 비용을 추가합니다.\n",
        "* L1 규제: 가중치의 절댓값에 비례하는 비용이 추가됩니다.(가중치의 L1 노름(norm))\n",
        "* L2 규제: 가중치의 제곱에 비례하는 비용이 추가됩니다. (L2 norm), L2 규제는 신경망에서 가중치 감쇠(weight decay)라고도 부릅니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uAGLyLwSC7N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 코드 4-7 케라스에서 사용할 수 있는 가중치 규제\n",
        "from keras import regularizers\n",
        "\n",
        "# L1 규제\n",
        "regularizers.l1(0.001)\n",
        "\n",
        "# L2 규제 - 가중치 행렬의 모든 원소를 제곱하고 0.001을 곱하여 네트워크의 전체 손실에 더해진다는 의미\n",
        "# 이 페널티 항은 훈련할 때만 추가됩니다.\n",
        "regularizers.l2(0.001)\n",
        "\n",
        "# L1과 L2 규제 병행\n",
        "regularizers.l1_l2(l1=0.001, l2=0.001)\n",
        "\n",
        "# 실제 예제\n",
        "model.add(layers.Dense(16, kernel_regularizer=regularizers.l2(0.001), activation='relu'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SiJsCZg-SC7Q",
        "colab_type": "text"
      },
      "source": [
        "### 4.4.3 드롭아웃 추가\n",
        "\n",
        "신경망을 위해 사용되는 규제 기법 중에서 가장 효과적이고 널리 사용되는 방법 중 하나입니다.\n",
        "\n",
        "네트워크 층에 드롭아웃을 적용하면 훈련하는 동안 무작위로 층의 일부 출력 특성을 제외시킵니다(0으로 만듭니다). 드롭아웃 비율은 0이 될 특성의 비율입니다. 보통 0.2~0.5 사이로 지정됩니다. **테스트 단계에서는 어떤 유닛도 드롭아웃되지 않습니다.** 그 대신에 층의 출력을 드롭아웃 비율에 비례하여 줄여 줍니다.\n",
        "\n",
        "왜 드롭아웃이 오버피팅을 줄이는 데 도움이 될까요? 제프리 힌튼은 은행에서 사용하는 부정 방지 메커니즘에서 착안했다고 합니다. 각 샘플에 대해 뉴런의 일부를 무작위하게 제거하면 뉴런의 부정한 협업을 방지하고 결국 과대적합을 감소시킨다는 것입니다. 즉, 출력 값에 노이즈를 추가하여 중요하지 않은 우연한 패턴을 깨뜨리는 것입니다. 노이즈가 없다면 네트워크가 이 패턴을 기억하기 시작할 것입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9eCTZ0rSC7R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 코드 4-8 드롭아웃 추가하기\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dropout(0.5))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CajzmZi-SC7Y",
        "colab_type": "text"
      },
      "source": [
        "정리하면 신경망에서 과대적합을 방지하기 위해 가장 널리 사용하는 방법은 다음과 같습니다.\n",
        "* 훈련 데이터를 더 모읍니다.\n",
        "* 네트워크의 용량을 감소시킵니다.\n",
        "* 가중치 규제를 추가합니다.\n",
        "* 드롭아웃을 추가합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmosZBDXSC7Z",
        "colab_type": "text"
      },
      "source": [
        "## 4.5 보편적인 머신 러닝 작업 흐름"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8QEzI6PSC7a",
        "colab_type": "text"
      },
      "source": [
        "### 4.5.1 문제 정의와 데이터셋 수집\n",
        "\n",
        "먼저 주어진 문제를 정의해야 합니다.\n",
        "* 입력 데이터는 무엇인가? 어떤 것을 예측하려고 하는가?\n",
        "* 문제가 어떤 종류인가? 이진 분류, 다중 분류, 스칼라 회귀, 벡터 회귀, 다중 레이블 다중 분류, 군집, 생성, 강화 학습...\n",
        "\n",
        "입력과 출력이 무엇인지와 어떤 데이터를 사용할 것인지 알기 전까지는 다음 단계로 넘어갈 수 없으므로 가설을 세워야 합니다.\n",
        "* 주어진 입력으로 출력을 예측할 수 있다고 가설을 세웁니다.\n",
        "* 가용한 데이에 입력과 출력 사이의 관계를 학습하는 데 충분한 정보가 있다고 가설을 세웁니다.\n",
        "\n",
        "모델이 작동하기 전까지 이는 가설에 불과하기 때문에 검증이 필요합니다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7hcavvDSC7b",
        "colab_type": "text"
      },
      "source": [
        "### 4.5.2 성공 지표 선택\n",
        "\n",
        "어떤 것을 제어하려면 관측할 수 있어야 합니다. 성공하기 위해서는 성공은 무엇인가를 정의해야 합니다. 성공의 지표가 모델이 최적화할 손실 함수를 선택하는 기준이 됩니다.\n",
        "* 클래스 분포가 균일한 분류 문제에서는 정확도와 ROC AUC가 일반적인 지표입니다.\n",
        "* 클래스 분포가 불균일한 문제에서는 정밀도와 재현율을 사용할 수 있습니다.\n",
        "* 랭킹 문제나 다중 레이블 문제에는 평균 정밀도를 사용할 수 있습니다.\n",
        "\n",
        "머신 러닝의 다양한 성공 지표가 여러 가지 종류의 문제에 어떻게 관련되어 있는지 알고 싶다면 kaggle 공부를 하시는게 좋습니다.  \n",
        "저도 kaggle 시작한지는 얼마 되지는 않았지만 다양한 대회가 있기 때문에 일단 한 competition에 참여해서 직접 부딪혀 보면서 경험하는 것이 실력 향상의 지름길인것 같습니다!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yOzDOomSC7c",
        "colab_type": "text"
      },
      "source": [
        "### 4.5.3 평가 방법 선택\n",
        "\n",
        "앞서 정리한 홀드아웃 검증 세트 분리, K-겹 교차 검증, 반복 K-겹 교차 검증 중 하나를 선택하면 됩니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zR_i7KFSC7d",
        "colab_type": "text"
      },
      "source": [
        "### 4.5.4 데이터 준비\n",
        "\n",
        "무엇을 훈련할지와 무엇을 최적화할지, 그리고 어떻게 평가할지를 정했다면 거의 모델을 훈련시킬 준비가 되었습니다. 하지만 먼저 머신 러닝 모델에 주입할 데이터를 구성해야 합니다. 위의 4.3절을 참고하면 좋습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zx81z2zSC7e",
        "colab_type": "text"
      },
      "source": [
        "### 4.5.5 기본보다 나은 모델 훈련하기\n",
        "\n",
        "이 단계의 목표는 **통계적 검정력**(statistical power)을 달성하는 것입니다. 검정력은 우리가 세운 가설이 참일 때 이를 채택할 확률을 말합니다.\n",
        "\n",
        "즉 아주 단순한 모델보다 나은 수준의 작은 모델을 개발합니다. IMDB 예에서는 0.5보다 높은 정확도를 갖는 것입니다. 통계적 검정력을 달성하는 것이 항상 가능하지는 않습니다. 여러 개의 타당성 있는 네트워크 구조를 시도해 보고 무작위로 예측하는 모델보다 낫지 않다면 입력 데이터에 존재하지 않는 것을 얻으려 하는 것일 겁니다.\n",
        "\n",
        "2개의 가설이 있다는 것을 기억해야 합니다!\n",
        "* 주어진 입력으로 출력을 예측할 수 있다는 가설\n",
        "* 가용한 데이터에 입력과 출력 사이의 관계를 학습하는 데 충분한 정보가 있다는 가설\n",
        "\n",
        "이 가설이 잘못된 것이면 기획부터 다시 해야 하고 잘 진행된다면 세 가지 중요한 선택을 해야 합니다.\n",
        "* **마지막 층의 활성화 함수**: 네트워크의 출력에 필요한 제한을 가합니다.\n",
        "* **손실 함수**: 풀려고 하는 문제의 종류에 적합해야 합니다.\n",
        "* **최적화 설정**: 옵티마이저와 학습률을 정해야 합니다. 대부분의 경우 rmsprop과 기본 학습률을 사용하는 것이 무난합니다.\n",
        "\n",
        "성공 지표는 직접 최적화하는 것이 항상 가능하지 않기 때문에 분류 작업에는 크로스엔트로피처럼 ROC AUC를 대신할 지표를 최적화하는 것이 보통입니다. 또한 손실 함수는 미니 배치 데이터에서 계산이 가능해야 하고 미분 가능해야 합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPhZOkSTSC7f",
        "colab_type": "text"
      },
      "source": [
        "자주 사용하는 옵티마이저 중에 'rmsprop', 'adam'은 기본 학습률이 0.001이고 'sgd', 'adagrad'는 0.01입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTaRguRgSC7g",
        "colab_type": "text"
      },
      "source": [
        "| 문제 유형 | 마지막 층의 활성화 함수 | 손실 함수 |\n",
        "| -------- | ------ | ------- |\n",
        "|이진 분류 | 시그모이드 | binary_crossentropy |\n",
        "|단일 레이블 다중 분류 | 소프트맥스 | categorical_crossentropy |\n",
        "|다중 레이블 다중 분류 | 시그모이드 | binary_crossentropy |\n",
        "|임의 값에 대한 회귀 | 없음 | mse |\n",
        "|0과 1사이 값에 대한 회귀 | 시그모이드 | mse 또는 binary_crossentropy |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-enBCRcaSC7h",
        "colab_type": "text"
      },
      "source": [
        "### 4.5.6 몸집 키우기: 과대적합 모델 구축\n",
        "\n",
        "통계적 검정력을 가진 모델을 얻었다면 이제 모델이 충분히 성능을 내는지 질문해야 합니다. 충분한 층과 파라미터가 있는지 체크해야 합니다. 머신 러닝은 최적화와 일반화 사이의 경계를 찾는 것입니다. 그러므로 먼저 과대적합된 모델을 만들어야 합니다.\n",
        "\n",
        "* 층을 추가합니다.\n",
        "* 층의 크기를 키웁니다.\n",
        "* 더 많은 epoch 동안 훈련합니다.\n",
        "\n",
        "훈련과 검증 지표, 훈련 손실과 검증 손실의 모니터를 통해 과대적합 시점을 찾고 이제 규제와 모델 튜닝을 통해 이상적인 모델을 만듭니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUY9BVB1SC7h",
        "colab_type": "text"
      },
      "source": [
        "### 4.5.7 모델 규제와 하이퍼파라미터 튜닝\n",
        "\n",
        "이 단계가 대부분의 시간을 차지합니다. 반복적으로 모델을 수정하고 훈련하고 검증 데이터에서 평가합니다. 그리고 다시 수정하고 가능한 좋은 모델을 얻을 때까지 반복합니다. 다음은 적용해 볼 것들입니다.\n",
        "* 드롭아웃 추가\n",
        "* 층 추가 또는 제거를 통한 다른 구조 시도\n",
        "* L1 이나 L2 또는 두 가지 규제 모두 추가\n",
        "* 하이퍼파라미터 변경(층의 유닛 수나 옵티마이저의 학습률)\n",
        "* 선택적으로 특성 공학(feature engineering) 시도"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Epu-d5q9SC7i",
        "colab_type": "text"
      },
      "source": [
        "검증 과정에서 얻은 피드백을 사용하여 모델을 튜닝할 때마다 이를 많이 반복하게 되면 결국 모델이 검증 과정에 대해 과대적합될 것을 주의해야 합니다. 마지막으로 테스트 과정에서 테스트 세트의 성능이 검증 데이터에서 측정한 것보다 많이 나쁘다면, 검증 과정에 전혀 신뢰성이 없거나 모델의 하이퍼파라미터를 튜닝하는 동안 검증 데이터에 과대적합된 것입니다. 이런 경우엔 좀 더 신뢰할 만한 평가 방법으로 바꾸는 것이 좋습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WMCrQr2SC7j",
        "colab_type": "text"
      },
      "source": [
        "## 4.6 요약\n",
        "\n",
        "* 주어진 문제와 훈련 데이터 정의\n",
        "* 성공 지표 선정, 검증 데이터에서 모니터링할  지표 선정\n",
        "* 평가 방법 결정\n",
        "* 통계적 검정력 있는 첫 번째 모델 만들기\n",
        "* 과대적합된 모델 만들기\n",
        "* 모델 규제와 하이퍼파라미터 튜닝"
      ]
    }
  ]
}